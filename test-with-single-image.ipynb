{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU03adzBtgOX"
   },
   "source": [
    "##Extracting HOG Features of a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:39.811378Z",
     "iopub.status.busy": "2023-02-18T07:34:39.810934Z",
     "iopub.status.idle": "2023-02-18T07:34:40.304669Z",
     "shell.execute_reply": "2023-02-18T07:34:40.303532Z",
     "shell.execute_reply.started": "2023-02-18T07:34:39.811296Z"
    },
    "id": "boLfa90x5iqf"
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "import cv2\n",
    "import glob\n",
    "import skimage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeRLsHVWg42r"
   },
   "source": [
    "When we give an image path, get_hog function will return the HOG features of the image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:40.306621Z",
     "iopub.status.busy": "2023-02-18T07:34:40.306350Z",
     "iopub.status.idle": "2023-02-18T07:34:40.313682Z",
     "shell.execute_reply": "2023-02-18T07:34:40.312467Z",
     "shell.execute_reply.started": "2023-02-18T07:34:40.306595Z"
    },
    "id": "vg-_u-6dvae2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def hog_pred(path):\n",
    "  img = imread(path)\n",
    "  img = skimage.transform.resize(img, (299, 299, 3))   \n",
    "        \n",
    "  fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "        \n",
    "        \n",
    "  test_img = hog_image.reshape(1,299*299)\n",
    "\n",
    "  hog_model = joblib.load('/kaggle/input/hand-crafted-feature-models/HOG_LR_Clf.joblib')\n",
    "\n",
    "  pred = hog_model.predict(test_img)\n",
    "\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXUc1K68hSb8"
   },
   "source": [
    "When we give the path of the test image, get_gist function will return the GIST features of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:40.317046Z",
     "iopub.status.busy": "2023-02-18T07:34:40.316700Z",
     "iopub.status.idle": "2023-02-18T07:34:40.326172Z",
     "shell.execute_reply": "2023-02-18T07:34:40.325365Z",
     "shell.execute_reply.started": "2023-02-18T07:34:40.317012Z"
    },
    "id": "1kbakb_37YUP"
   },
   "outputs": [],
   "source": [
    "def gist_pred(path):\n",
    "        \n",
    "        img = imread(path)\n",
    "        #img = skimage.transform.resize(img, (299, 299, 3))   \n",
    "        \n",
    "        # Convert the image from BGR to RGB format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Reshape the image to a one-dimensional array\n",
    "        img = img.reshape(-1)\n",
    "        \n",
    "        \n",
    "        # Extract the GIST features using OpenCV's calcHist function\n",
    "        gist_features = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "        test_img = gist_features.reshape(gist_features.shape[1],gist_features.shape[0])\n",
    "\n",
    "        gist_model = joblib.load('/kaggle/input/hand-crafted-feature-models/GIST_LR_Clf.joblib')\n",
    "\n",
    "        pred = gist_model.predict(test_img)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDzaa_-sQ50u"
   },
   "source": [
    "##pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:40.329466Z",
     "iopub.status.busy": "2023-02-18T07:34:40.328478Z",
     "iopub.status.idle": "2023-02-18T07:34:40.337448Z",
     "shell.execute_reply": "2023-02-18T07:34:40.336351Z",
     "shell.execute_reply.started": "2023-02-18T07:34:40.329424Z"
    },
    "id": "tMo-ihOaQ4ub"
   },
   "outputs": [],
   "source": [
    "def loadImages(img_path):\n",
    "  \n",
    "  img = imread(img_path)\n",
    "  img = skimage.transform.resize(img, (224, 224, 3))        \n",
    "  IMG = np.array(img,dtype=np.float64)\n",
    "\n",
    "  test_img = IMG.reshape(1,224,224,3)\n",
    "        \n",
    "  return test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdH4ilwhRZid"
   },
   "source": [
    "##Chexnet\n",
    " extracting features using chexnet model  on a sinlge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:40.339712Z",
     "iopub.status.busy": "2023-02-18T07:34:40.339220Z",
     "iopub.status.idle": "2023-02-18T07:34:42.417970Z",
     "shell.execute_reply": "2023-02-18T07:34:42.416889Z",
     "shell.execute_reply.started": "2023-02-18T07:34:40.339672Z"
    },
    "id": "Mxoy0eL9RXqG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.420331Z",
     "iopub.status.busy": "2023-02-18T07:34:42.419600Z",
     "iopub.status.idle": "2023-02-18T07:34:42.427472Z",
     "shell.execute_reply": "2023-02-18T07:34:42.426601Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.420295Z"
    },
    "id": "RqCcoIkkWCdL"
   },
   "outputs": [],
   "source": [
    "def chxnet_pred(path):\n",
    "  x_test = loadImages(path)\n",
    "  ChexNet_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3), pooling='max')\n",
    "\n",
    "  # summarize feature map shapes\n",
    "  for i in range(len(ChexNet_model.layers)):\n",
    "      layer = ChexNet_model.layers[i]\n",
    "      # check for conv5_ layer\n",
    "      if 'conv5_block3_concat' not in layer.name:\n",
    "        continue\n",
    "  # redefine model to output right after the 333th (conv5_block3_concat) layer\n",
    "  chex_feat_model = Model(inputs=ChexNet_model.inputs, outputs=ChexNet_model.layers[333].output)\n",
    "\n",
    "  # feature extraction train set using ChexNet\n",
    "  feat_chxnet = chex_feat_model.predict(x_test)\n",
    "\n",
    "  chxnet_model = keras.models.load_model('/kaggle/input/saved-model-file-weights/ChexNet_feat_CLF_model.h5')\n",
    "\n",
    "  pred= chxnet_model.predict(feat_chxnet)\n",
    "  classes = np.argmax(pred,axis = 1)\n",
    "\n",
    "\n",
    "  return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHO6CmeISkl4"
   },
   "source": [
    "###Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.429036Z",
     "iopub.status.busy": "2023-02-18T07:34:42.428592Z",
     "iopub.status.idle": "2023-02-18T07:34:42.443527Z",
     "shell.execute_reply": "2023-02-18T07:34:42.442258Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.429008Z"
    },
    "id": "vOxnXCfFSkKD"
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.445361Z",
     "iopub.status.busy": "2023-02-18T07:34:42.445055Z",
     "iopub.status.idle": "2023-02-18T07:34:42.454018Z",
     "shell.execute_reply": "2023-02-18T07:34:42.453101Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.445331Z"
    },
    "id": "s6jAfh72ZIDS"
   },
   "outputs": [],
   "source": [
    "def dense_pred(path):\n",
    "  x_test = loadImages(path)\n",
    "  # Instantiate convolutional base of DenseNet 169\n",
    "\n",
    "  dense169_model = DenseNet169(weights='imagenet', include_top=False,input_shape=(224,224, 3))\n",
    "  # summarize feature map shapes\n",
    "  for i in range(len(dense169_model.layers)):\n",
    "      layer = dense169_model.layers[i]\n",
    "  # check for conv5_ layer\n",
    "      if 'conv5_block32_concat' not in layer.name:\n",
    "          continue\n",
    "\n",
    "  # redefine model to output right after the 592nd (conv5_block3_concat) layer\n",
    "  dense169_feat_model = Model(inputs=dense169_model.inputs, outputs=dense169_model.layers[592].output)\n",
    "\n",
    "  # feature extraction train set using DenseNet169\n",
    "  feat = dense169_feat_model.predict(x_test)\n",
    "\n",
    "  densenet_model = keras.models.load_model('/kaggle/input/saved-model-file-weights/densenet_feat_CLF_model.h5')\n",
    "\n",
    "  pred= densenet_model.predict(feat)\n",
    "  classes = np.argmax(pred,axis = 1)\n",
    "\n",
    "  return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVZveQ8mTU1W"
   },
   "source": [
    "###inception net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.455323Z",
     "iopub.status.busy": "2023-02-18T07:34:42.455066Z",
     "iopub.status.idle": "2023-02-18T07:34:42.469503Z",
     "shell.execute_reply": "2023-02-18T07:34:42.468250Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.455298Z"
    },
    "id": "RXNnMzUwTZ-x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Activation,AveragePooling2D,MaxPool2D, Dropout, Conv2D, MaxPooling2D, Flatten,GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.472873Z",
     "iopub.status.busy": "2023-02-18T07:34:42.472524Z",
     "iopub.status.idle": "2023-02-18T07:34:42.480512Z",
     "shell.execute_reply": "2023-02-18T07:34:42.479176Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.472846Z"
    },
    "id": "5_wUABj6VOFC"
   },
   "outputs": [],
   "source": [
    "def load_inp_Images(path):\n",
    "  img = cv2.imread(path)\n",
    "  img = skimage.transform.resize(img, (299, 299, 3))        \n",
    "  IMG = np.array(img,dtype=np.float64)\n",
    "  test_img = IMG.reshape(1,299,299,3)      \n",
    "        \n",
    "  return test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:34:42.482211Z",
     "iopub.status.busy": "2023-02-18T07:34:42.481979Z",
     "iopub.status.idle": "2023-02-18T07:34:42.492540Z",
     "shell.execute_reply": "2023-02-18T07:34:42.491555Z",
     "shell.execute_reply.started": "2023-02-18T07:34:42.482188Z"
    },
    "id": "uoEyOyFfeiRv"
   },
   "outputs": [],
   "source": [
    "def inp_pred(path):\n",
    "  test_data = load_inp_Images(path)\n",
    "  inp_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3), pooling='max')\n",
    "\n",
    "  # summarize feature map shapes\n",
    "  for i in range(len(inp_model.layers)):\n",
    "      layer = inp_model.layers[i]\n",
    "    # check for batch_normalization_ layer\n",
    "      if 'batch_normalization_' not in layer.name:\n",
    "          continue\n",
    "    \n",
    "  # redefine model to output right after the 305th (batch_normalization_93) layer\n",
    "  incep_feat_model = Model(inputs=inp_model.inputs, outputs=inp_model.layers[305].output)\n",
    "\n",
    "  feat_inp = incep_feat_model.predict(test_data)\n",
    "\n",
    "  inp_model = keras.models.load_model('/kaggle/input/saved-model-file-weights/Inception_feat_CLF_model.h5')\n",
    "\n",
    "  pred = inp_model.predict(feat_inp)\n",
    "  classes = np.argmax(pred,axis = 1)\n",
    "\n",
    "  return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvOL81BHkojE"
   },
   "source": [
    "###Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:35:42.132366Z",
     "iopub.status.busy": "2023-02-18T07:35:42.132027Z",
     "iopub.status.idle": "2023-02-18T07:35:42.140907Z",
     "shell.execute_reply": "2023-02-18T07:35:42.139373Z",
     "shell.execute_reply.started": "2023-02-18T07:35:42.132336Z"
    },
    "id": "j-H8kVQmkq1p"
   },
   "outputs": [],
   "source": [
    "def ensemble_pred(path):\n",
    "\n",
    "  hog_predicted = hog_pred(path)\n",
    "  gist_predicted= gist_pred(path)\n",
    "  chxnet_predicted = chxnet_pred(path)\n",
    "  densenet_predicted =dense_pred(path)\n",
    "  inception_predicted = inp_pred(path)\n",
    "\n",
    "\n",
    "  # model_predictions is a list of predictions from multiple models\n",
    "  model_predictions = [hog_predicted, gist_predicted, chxnet_predicted, densenet_predicted, inception_predicted]\n",
    " # model_predictions = [hog_pred, gist_pred, chxnet_pred, densenet_pred, inception_pred]\n",
    "\n",
    "  # Stack the predictions along axis=0\n",
    "  ensemble3_prediction = np.stack(model_predictions, axis=0)\n",
    "\n",
    "  # Check the number of dimensions of the ensemble_prediction array\n",
    "  if ensemble3_prediction.ndim == 1:\n",
    "     ensemble3_prediction = ensemble3_prediction[0]\n",
    "  else:\n",
    "      # Take the mean of the stacked predictions along axis=0\n",
    "      ensemble3_prediction = np.mean(ensemble3_prediction, axis=0)\n",
    "\n",
    "  # Convert the average predictions back to the original format\n",
    "  ensemble3_prediction = ensemble3_prediction.flatten()\n",
    "\n",
    "  # Convert the predicted class probabilities into actual class labels\n",
    "  ensemble3_prediction = np.round(ensemble3_prediction).astype(int)\n",
    "\n",
    "  if ensemble3_prediction[0] == 1:\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    print(\"Patient with Tuberculosis\")\n",
    "  else:\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(\"No Tuberculosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with an Xray of a patient with Tuberculosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T07:35:46.810943Z",
     "iopub.status.busy": "2023-02-18T07:35:46.810572Z",
     "iopub.status.idle": "2023-02-18T07:36:02.054867Z",
     "shell.execute_reply": "2023-02-18T07:36:02.054001Z",
     "shell.execute_reply.started": "2023-02-18T07:35:46.810914Z"
    },
    "id": "D3pTMbbb3xcH",
    "outputId": "14e7439a-3ebd-40e3-a2eb-0b348c323ad2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 1s 999ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "---------------------------------------------------------------------------------\n",
      "Patient with Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "path = '/kaggle/input/test-image-xrays/Tuberculosis Xray.jpg'\n",
    "ensemble_pred(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a Normal Xray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T07:45:54.121718Z",
     "iopub.status.busy": "2023-02-18T07:45:54.121329Z",
     "iopub.status.idle": "2023-02-18T07:46:10.002043Z",
     "shell.execute_reply": "2023-02-18T07:46:10.001072Z",
     "shell.execute_reply.started": "2023-02-18T07:45:54.121688Z"
    },
    "id": "n6dVcFPW3x53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "-----------------------------------------------------------------------------------\n",
      "Normal patient\n"
     ]
    }
   ],
   "source": [
    "path = '/kaggle/input/test-image-xrays/Normal Xray.jpg'\n",
    "ensemble_pred(path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
